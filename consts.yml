theme: SPACELAB

# Environment variable specifying location of AWS key file
credentials: WEBFISH_CREDS

# Profile name to use from the above file
cred_profile_name: hpc-wasabi-user

# URL to connect to S3 on
endpoint_url: "https://s3.us-west-1.wasabisys.com"

# S3 region to connect to
region_name: us-west-1

# S3 bucket to access
bucket_name: hpc-wasabi

test_root: tests/webfish_test_root
test_bucket_name: webfish-sandbox

file_locations:
  source:
    root: /groups/CaiLab/analyses/
    dataset_format: "{user}/{dataset}/{analysis}"
    prefix: "analyses/"
  raw:
    root: /groups/CaiLab/personal/
    dataset_format: "{user}/raw/{dataset}"
    prefix: "raw/"


# Folder to save file manifests and syncing information to, both on
#   server and on client (running instance of webapp)
sync_folder: monitoring/

# Location to save files that have been processed with preuploader functions
preupload_root: /groups/CaiLab/personal/lincoln/webfish_preupload/

# Folder on client (webapp) to save all downloaded data/analysis files that
#   are used in the webapp
local_store: webfish_data/

# ----------------------------

# Specification of pages that use the data infrastructure
pages:
  datavis:
    title: "Data Visualization"
    description: "Visualize decoded genes and segmentation"
    file: "datavis.py"
    # Variable fields in the files required by this page
    variables: [ "position", "channel" ]

  dotdetection:
    title: "Dot Detection"
    description: "Visualize and run dot detection and raw images"
    file: "dotdetection.py"
    variables: [ "hyb", "position" ]

  submit_analysis:
    title: "Submit New Analysis"
    description: "Select parameters to submit a new analysis run on the HPC"
    file: "submission.py"

# Listing of files from master_root / dataset_root (i.e. analyzed data files)
# Note that this is an abbreviated format, can also specify pattern,
#   preupload function as done below for dot detection
# Note use of format {fields} in patterns
file_patterns:
  source:
    segmentation:
      "MMStack_Pos{position}/Segmentation/labeled_img.tif"
    dots_csv:
      "MMStack_Pos{position}/Segmentation/Channel_{channel}/gene_locations_assigned_to_cell.csv"
    dots_csv_unseg:
      "MMStack_Pos{position}/Decoded/Channel_{channel}/pre_seg_diff_1_minseeds_3_filtered.csv"
    cell_info:
      "MMStack_Pos{position}/Segmentation/Channel_{channel}/cell_info.csv"
    onoff_intensity_plot:
      "MMStack_Pos{position}/False_Positive_Rate_Analysis/Channel_{channel}/On-Off-Barcode-Intensity-Analysis.png"
    onoff_sorted_plot:
      "MMStack_Pos{position}/On_Off_Barcode_Plot/Channel_{channel}/On_Off_Sorted_Barcode_Plot.png"
    falsepositive_txt:
      "MMStack_Pos{position}/False_Positive_Rate_Analysis/Channel_{channel}/false_positives_after_segmentation.txt"
    offsets_json:
      "MMStack_Pos{position}/offsets.json"
    dot_locations:
      "MMStack_Pos{position}/Dot_Locations/locations.csv"
    avg_brightness:
      "MMStack_Pos{position}/Dot_Locations/Average_Brightness_Analysis.csv"
    biggest_jump:
      "MMStack_Pos{position}/Dot_Locations/Biggest_Jump_Histograms/HybCycle_{hyb}_Jump.png"
    preprocess_check:
      "MMStack_Pos{position}/PreProcess_Check/HybCycle_{hyb}.png"
    alignment_check:
      "MMStack_Pos{position}/Alignment_Checks/Aligned_and_Stacked_DAPI_S.tif"

  raw:
    hyb_fov:
      pattern: "HybCycle_{hyb}/MMStack_Pos{position}.ome.tif"
      preupload: "compress_raw_im_2"
    positions:
      pattern: "{posfilename}.pos"
    background_im:
      pattern: "final_background/MMStack_Pos{position}.ome.tif"
      preupload: "compress_raw_im_2"
    presegmentation_im:
      pattern: "segmentation/MMStack_Pos{position}.ome.tif"
      preupload: "compress_raw_im_2"

  # Listing of output files generated from the source files
  # - "pattern" is the format string pattern for the output file,
  # - "requires" is an array of keys from source_files or raw_files that
  #   specifies what input files are needed. Alternative sources that can
  #   substitute for another are denoted with pipes key_1 | key_2
  # - "generator" is the name of a function from the generator_class
  #   that will produce the output file from the input files.
  output:
    mesh:
      pattern: "MMStack_Pos{position}/labeled_mesh.json"
      requires: ["segmentation"]
      generator: "generate_mesh"
    dots:
      pattern: "MMStack_Pos{position}/dots_um_with_colors.csv"
      requires: ["dots_csv | dots_csv_unseg"]
      generator: "generate_dots"
